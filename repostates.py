#====================================================MARK[SUCCESS]
#   R E P O S T A T E S . P Y   | Last Update |  [v.301068-1250] - OFFLINE/LONG COMMAND SUPPORT
#============================================Program by CreativeHD
import requests
import time
import json
import random 
import os 
import sys 
import socket           # Standard Library
import contextlib       # Standard Library
from concurrent.futures import ThreadPoolExecutor, as_completed, TimeoutError 
from typing import Dict, Any, Optional
import re # üÜï Import: ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÅ‡∏¢‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á

# =================================================================
# 0. ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Log ‡πÅ‡∏•‡∏∞ Log Redirection
# =================================================================
LOG_FILE_NAME = "repostates_log.txt"

@contextlib.contextmanager
def redirect_stdout_to_file(filename):
    """Context manager to redirect all print/stdout to a log file."""
    original_stdout = sys.stdout
    with open(filename, 'a', encoding='utf-8') as f:
        sys.stdout = f
        try:
            yield
        finally:
            sys.stdout = original_stdout

# =================================================================
# 1. ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà (CONFIGS)
# =================================================================

MONITORING_SERVER_PORT = 5000 
MINER_API_PORT = 4048 # üö® FIX: ‡∏û‡∏≠‡∏£‡πå‡∏ï API ‡∏Ç‡∏≠‡∏á Miner (‡πÄ‡∏ä‡πà‡∏ô ccminer/XMRig) 
IP_STORAGE_FILE = "server_ip.json" 

# üö® FIX: ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏£‡∏±‡∏ô Miner (‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏à‡∏£‡∏¥‡∏á)
COMMAND_LINE_EXAMPLE = "./ccminer -a verus -o stratum+tcp://ap.luckpool.net:3956 -u RHq9fSNPPXraAVQnq3SkNqgzrnADwGbvru.HuaweiY92018V -p hybrid -t 7"
DEFAULT_WORKER_TAGS = "Offline-Direct"
DEFAULT_WORKER_PASS = "x"

# *** ‚ö†Ô∏è IP ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏ß‡πà‡∏≤ Server ‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà (‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô 0.0.0.0 ‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏≠‡∏á) ***
DEFAULT_MONITORING_SERVER_IP = "0.0.0.0" 

# Endpoint ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Discovery
DISCOVERY_ENDPOINT_FORMAT = f"http://{{host}}:{MONITORING_SERVER_PORT}/Miner_Server/discovery" 

# ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
REPORT_INTERVAL_SEC = 60 
MAX_RETRIES = 5
RETRY_DELAY = 10 
DISCOVERY_RETRY_THRESHOLD = 3 

# ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Subnet Scan
SUBNET_SCAN_TIMEOUT_SEC = 10 # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏™‡πÅ‡∏Å‡∏ô Subnet ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
IP_TIMEOUT_SEC = 0.5         # Timeout ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡∏≠‡∏á‡∏ï‡πà‡∏≠ IP ‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏Ñ‡∏£‡∏±‡πâ‡∏á
MAX_SCAN_WORKERS = 15        # ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô Thread ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πÅ‡∏Å‡∏ô‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
TARGET_SUBNET_PREFIX = "192.168.1." # ‡∏ß‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡∏≠‡∏Ç‡πà‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏™‡πÅ‡∏Å‡∏ô

# =================================================================
# 2. GLOBAL STATE
# =================================================================
CURRENT_MONITORING_SERVER_IP: str = ""
REPORT_URL: str = ""
REPORT_FAILURE_COUNT: int = 0

# =================================================================
# 3. UTILITY FUNCTIONS (IP Discovery and Persistence)
# =================================================================
# (‡∏™‡πà‡∏ß‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏á‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ IP)
def get_local_ip() -> str:
    """Gets the local IP address of the client machine."""
    try:
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80)) 
        ip = s.getsockname()[0]
        s.close()
        return ip
    except Exception:
        return "127.0.0.1"

def load_server_ip() -> str:
    """Loads the last known Server IP from server_ip.json."""
    try:
        with open(IP_STORAGE_FILE, 'r') as f:
            data = json.load(f)
            ip = data.get('server_ip')
            if ip:
                print(f" [LOAD] Loaded last known IP from {IP_STORAGE_FILE}: {ip}")
                return ip
    except Exception:
        print(f" [LOAD] {IP_STORAGE_FILE} not found or corrupted. Using default.")
        
    return DEFAULT_MONITORING_SERVER_IP

def save_server_ip(ip: str):
    """Saves the newly discovered Server IP to server_ip.json."""
    try:
        with open(IP_STORAGE_FILE, 'w') as f:
            json.dump({"server_ip": ip}, f, indent=4) 
        print(f" [INFO] New Server IP saved to {IP_STORAGE_FILE}: {ip}")
    except Exception as e:
        print(f" [ERROR] Could not save IP to {IP_STORAGE_FILE}: {e}")

def discover_server_ip(host: str) -> Optional[str]:
    """Attempts to connect to the discovery endpoint on the given host."""
    discovery_url = DISCOVERY_ENDPOINT_FORMAT.format(host=host)
    
    if host == "0.0.0.0" or host == "":
        return None

    try:
        response = requests.get(discovery_url, timeout=IP_TIMEOUT_SEC) 
        
        if response.status_code == 200:
            try:
                data = response.json()
                discovered_host = data.get('HostAddress') 

                if discovered_host:
                    print(f" [SUCCESS] Server reached at {host}. Confirmed Host: {discovered_host}")
                    return discovered_host 
            except json.JSONDecodeError:
                pass
                
    except requests.exceptions.RequestException:
        pass 
        
    return None

def run_subnet_scan(skip_ips: list) -> Optional[str]:
    """Runs a concurrent scan over the target subnet with a time limit."""
    print(f" [NETSCAN] Starting full subnet scan ({TARGET_SUBNET_PREFIX}1 to 254). Max {SUBNET_SCAN_TIMEOUT_SEC}s...")
    
    ips_to_scan = [f"{TARGET_SUBNET_PREFIX}{i}" for i in range(1, 255) 
                   if f"{TARGET_SUBNET_PREFIX}{i}" not in skip_ips]
    
    try:
        with ThreadPoolExecutor(max_workers=MAX_SCAN_WORKERS) as executor:
            future_to_ip = {executor.submit(discover_server_ip, ip): ip for ip in ips_to_scan}
            
            for future in as_completed(future_to_ip.keys(), timeout=SUBNET_SCAN_TIMEOUT_SEC):
                result_ip = future.result()
                if result_ip:
                    print(f" [NETSCAN SUCCESS] Server found in concurrent scan: {result_ip}")
                    executor.shutdown(wait=False, cancel_futures=True)
                    return result_ip
                    
    except TimeoutError: 
        print(f" [NETSCAN TIMEOUT] Subnet scan timed out after {SUBNET_SCAN_TIMEOUT_SEC} seconds.")
    except Exception as e:
        print(f" [NETSCAN ERROR] An error occurred during concurrent scan: {e}")
        
    return None

def update_server_ip_if_needed():
    """
    ‡∏ï‡∏£‡∏£‡∏Å‡∏∞‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î, Discovery, ‡πÅ‡∏•‡∏∞‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å IP Server
    """
    global CURRENT_MONITORING_SERVER_IP, REPORT_URL, REPORT_FAILURE_COUNT
    
    last_known_ip = load_server_ip()
    local_ip = get_local_ip()
    
    print(f" [INIT] Local IP: {local_ip}. Last Known IP: {last_known_ip}")
    discovered_ip: Optional[str] = None
    
    # --- 1. PRIORITY 1: ‡∏•‡∏≠‡∏á IP ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏£‡∏π‡πâ‡∏à‡∏±‡∏Å
    if last_known_ip != DEFAULT_MONITORING_SERVER_IP:
        print(f" [P1 TRY] Checking last known IP: {last_known_ip}")
        discovered_ip = discover_server_ip(last_known_ip)

    # --- 2. PRIORITY 2: ‡∏•‡∏≠‡∏á IP ‡∏Ç‡∏≠‡∏á‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á Client ‡πÄ‡∏≠‡∏á
    if not discovered_ip:
        print(f" [P2 TRY] Checking Localhost/Self IP: {local_ip}")
        discovered_ip = discover_server_ip("127.0.0.1")

    # --- 3. PRIORITY 3: Full Subnet Scan
    if not discovered_ip:
        skip_ips = [last_known_ip, local_ip, "127.0.0.1"]
        discovered_ip = run_subnet_scan(skip_ips)
        
    # --- 4. Finalizing ---
    if discovered_ip:
        
        if discovered_ip != last_known_ip:
            print(f" [UPDATE] Server IP changed from {last_known_ip} to {discovered_ip}. Saving to file.")
            save_server_ip(discovered_ip)
        else:
             print(f" [CONFIRM] Server IP {discovered_ip} is consistent with last known IP.")
             
        CURRENT_MONITORING_SERVER_IP = discovered_ip
        
    else:
        # ‡∏ñ‡πâ‡∏≤‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ IP ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î/‡∏Ñ‡πà‡∏≤‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô/Local IP ‡πÄ‡∏õ‡πá‡∏ô‡∏ó‡∏≤‡∏á‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
        fallback_ip = last_known_ip if last_known_ip != DEFAULT_MONITORING_SERVER_IP else local_ip
        CURRENT_MONITORING_SERVER_IP = fallback_ip
        print(f" [CRITICAL] All discovery failed. Using fallback IP for report: {CURRENT_MONITORING_SERVER_IP}")
        
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î URL ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    REPORT_URL = f"http://{CURRENT_MONITORING_SERVER_IP}:{MONITORING_SERVER_PORT}/report_stats"
    print(f" [CONFIG] Final Report URL: {REPORT_URL}")
    
    REPORT_FAILURE_COUNT = 0

# =================================================================
# 4. REPORTING LOGIC (NEW: Uses hardcoded Worker Info & Miner API)
# =================================================================

def get_worker_info_from_command(full_command: str) -> Dict[str, str]:
    """
    üÜï ‡∏î‡∏∂‡∏á‡∏ä‡∏∑‡πà‡∏≠ Worker ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô‡∏¢‡∏≤‡∏ß (‡∏ï‡∏≤‡∏°‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö -u <address>.<workername>)
    """
    try:
        # ‡πÉ‡∏ä‡πâ Regular Expression ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏Ñ‡πà‡∏≤‡∏´‡∏•‡∏±‡∏á -u ‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏ä‡πà‡∏≠‡∏á‡∏ß‡πà‡∏≤‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ
        match = re.search(r'-u\s+([^\s]+)', full_command)
        if match:
            full_user_address = match.group(1)
            # ‡πÅ‡∏¢‡∏Å‡πÄ‡∏≠‡∏≤‡∏ä‡∏∑‡πà‡∏≠ Worker ‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏´‡∏•‡∏±‡∏á‡∏à‡∏∏‡∏î‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢
            worker_name = full_user_address.split('.')[-1]
            if not worker_name:
                raise ValueError("Worker Name not found after '.'")
            
            print(f" [Config Extracted] Worker Name: {worker_name}")
            return {'Rname': worker_name, 
                    'Zone': DEFAULT_WORKER_TAGS, 
                    'Pass': DEFAULT_WORKER_PASS}
            
    except Exception as e:
        print(f" [Config Error] Failed to extract Worker Name from command: {e}. Using fallback.")
        
    return {'Rname': "Unknown-Offline-Worker", 
            'Zone': DEFAULT_WORKER_TAGS, 
            'Pass': DEFAULT_WORKER_PASS}

def get_actual_miner_stats() -> Dict[str, float]:
    """
    üÜï ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å Miner API ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà‡∏ö‡∏ô 127.0.0.1:<MINER_API_PORT>
    """
    MINER_API_URL = f"http://127.0.0.1:{MINER_API_PORT}/"
    try:
        # ‡πÄ‡∏û‡∏¥‡πà‡∏° timeout 5 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö request
        response = requests.get(MINER_API_URL, timeout=5) 
        
        # üö® ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏£‡∏£‡∏∞‡∏ß‡∏±‡∏á: ‡∏ï‡πâ‡∏≠‡∏á‡∏õ‡∏£‡∏±‡∏ö‡πÇ‡∏Ñ‡πâ‡∏î‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏ï‡∏≤‡∏° API ‡∏Ç‡∏≠‡∏á Miner ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
        data = response.json()

        # ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏™‡∏°‡∏°‡∏ï‡∏¥‡∏ê‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏£‡∏¥‡∏á:
        # *********** ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏´‡∏≤‡∏Å Miner API ‡∏ï‡∏≠‡∏ö‡πÑ‡∏°‡πà‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô ***********
        hashrate_sols = data.get('total_hashrate', 0.0)
        shares_sent = data.get('accepted_shares', 0.0) 
        # ***************************************************************
        
        if hashrate_sols > 0.0:
            print(f" [STATS] Successfully read stats from Miner API: {hashrate_sols/1000000:.2f} M Sols")
            return {'hashrate_sols': hashrate_sols, 'shares_sent': shares_sent}
            
    except requests.exceptions.RequestException as e:
        print(f" [STATS ERROR] Could not connect to Miner API {MINER_API_URL}: {e}")
    except json.JSONDecodeError:
        print(f" [STATS ERROR] Miner API returned non-JSON response. (Check API port/format)")
    except Exception as e:
        print(f" [STATS ERROR] An unexpected error occurred: {e}")
            
    # Fallback: ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏™‡∏∏‡πà‡∏°/‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏ñ‡πâ‡∏≤ API ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
    print(f" [STATS FALLBACK] Using random data due to API failure.")
    return {'hashrate_sols': random.uniform(2000000.0, 3000000.0), 
            'shares_sent': 100.0 + random.randint(1, 50)}

def send_report(worker_name: str, worker_tags: str, worker_pass: str) -> bool:
    """Sends the worker status report to the monitoring server."""
    global REPORT_URL, REPORT_FAILURE_COUNT
    
    # üÜï ‡∏î‡∏∂‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏à‡∏£‡∏¥‡∏á‡∏à‡∏≤‡∏Å Miner API
    stats = get_actual_miner_stats() 

    # 1. ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Payload
    payload = {
        'worker_name': worker_name,
        'hashrate_sols': stats['hashrate_sols'],
        'shares_sent': stats['shares_sent'],
        'tags': worker_tags,         
        'worker_pass': worker_pass   
    }

    # 2. ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡∏™‡πà‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô
    for attempt in range(MAX_RETRIES):
        try:
            response = requests.post(REPORT_URL, json=payload, timeout=10) 
            
            if response.status_code == 200:
                print(f" [REPORT SUCCESS] {worker_name}: Sent {stats['hashrate_sols']/1000000:.2f} M Sols. (Tags: {worker_tags}, Pass: {worker_pass})")
                REPORT_FAILURE_COUNT = 0
                return True
            else:
                msg = response.json().get('message', 'N/A')
                print(f" [REPORT FAILED] Server status {response.status_code}. Attempt {attempt+1}/{MAX_RETRIES}: {msg}")

        except requests.exceptions.RequestException as e:
            print(f" [REPORT ERROR] Connect failed to {REPORT_URL}. Attempt {attempt+1}/{MAX_RETRIES}: {e}")

        if attempt < MAX_RETRIES - 1:
            time.sleep(RETRY_DELAY)

    # 3. ‡∏ñ‡πâ‡∏≤‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    REPORT_FAILURE_COUNT += 1 
    print(f" [CRITICAL] Failed to report stats after {MAX_RETRIES} attempts. Failure count: {REPORT_FAILURE_COUNT}")
    return False


# =================================================================
# 5. MAIN EXECUTION BLOCK 
# =================================================================
if __name__ == '__main__':
    
    with redirect_stdout_to_file(LOG_FILE_NAME):
        
        print(f"\n========================================================")
        print(f" [SESSION START] {time.ctime()}")
        print(f"========================================================")

        # üÜï ‡πÇ‡∏´‡∏•‡∏î Config ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Worker ‡∏à‡∏≤‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏£‡∏±‡∏ô‡∏¢‡∏≤‡∏ß
        worker_info = get_worker_info_from_command(COMMAND_LINE_EXAMPLE)
        WORKER_NAME = worker_info['Rname']
        WORKER_TAGS = worker_info['Zone'] 
        WORKER_PASS = worker_info['Pass']
        
        if WORKER_NAME == "Unknown-Offline-Worker":
            print(" [FATAL] Worker Name not set. Exiting.")
            sys.exit(1)
            
        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ IP
        update_server_ip_if_needed()
        
        print(f" [START] Starting reporting loop for worker {WORKER_NAME} every {REPORT_INTERVAL_SEC} seconds...")
        
        # 3. Main Loop
        while True:
            
            report_success = send_report(WORKER_NAME, WORKER_TAGS, WORKER_PASS) 
            
            # 4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÅ‡∏•‡∏∞‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Discovery ‡∏ã‡πâ‡∏≥
            if not report_success and REPORT_FAILURE_COUNT >= DISCOVERY_RETRY_THRESHOLD:
                print(f" [REDISCOVERY] Initiating server IP rediscovery due to {REPORT_FAILURE_COUNT} consecutive failures.")
                update_server_ip_if_needed()

            time.sleep(REPORT_INTERVAL_SEC)
